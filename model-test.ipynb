{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import queue\n",
    "\n",
    "import threading\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple('batch', ('before', 'after'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_file_list = glob.glob('resource/*.png')\n",
    "emoticon_file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(emoticon_file_list[-1])\n",
    "# image = image[:, :, (2, 1, 0)]\n",
    "# image = image / 2 ** 8\n",
    "# plt.imshow(image)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove white images\n",
    "\n",
    "for file in tqdm(emoticon_file_list):\n",
    "    \n",
    "    image = cv2.imread(file)\n",
    "    \n",
    "    if np.min(image) == 255:\n",
    "        print(file)\n",
    "        image = image[:, :, (2, 1, 0)]\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in tqdm(emoticon_file_list):\n",
    "    \n",
    "    image = cv2.imread(file)\n",
    "    \n",
    "    image = image[:, :, (2, 1, 0)]\n",
    "        \n",
    "    if image.shape[0] != image.shape[1]:\n",
    "        \n",
    "        white_image = np.ones((124, 124, 3), dtype=np.uint8) * 255\n",
    "        white_image[:image.shape[0], :image.shape[1], :image.shape[2]] = image\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(white_image)\n",
    "        plt.show()\n",
    "        print(file)\n",
    "        \n",
    "        im = Image.fromarray(white_image)\n",
    "        im.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punch_image(image, p=0.1):\n",
    "    \n",
    "    bool_mask = np.random.choice((True, False), image.shape[1:3], True, (1-p, p))\n",
    "    bool_mask = np.stack([bool_mask, bool_mask, bool_mask], axis=0)\n",
    "    \n",
    "    punched_image= np.where(bool_mask, image, np.ones(image.shape))\n",
    "    \n",
    "    return punched_image\n",
    "\n",
    "def blur_image(image, sigma=0.25):\n",
    "    blurred_image = gaussian_filter(image, sigma = (0, sigma, sigma))\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.rollaxis(image, 2, 0)\n",
    "# x.shape\n",
    "# y = np.rollaxis(x, 0, 3)\n",
    "# plt.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Punch test\n",
    "\n",
    "# for j in range(3):\n",
    "    \n",
    "#     file = np.random.choice(emoticon_file_list)\n",
    "    \n",
    "#     image = cv2.imread(file)\n",
    "#     image = image[:, :, (2, 1, 0)]\n",
    "#     image = image / 2 ** 8\n",
    "\n",
    "#     punched_image = image\n",
    "\n",
    "#     fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "\n",
    "#     for i in range(16):\n",
    "\n",
    "#         axes[i//4][i%4].imshow(punched_image, aspect='auto')\n",
    "\n",
    "#         punched_image = punch_image(punched_image, 0.15)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_list_to_tensor_batch(batch_list):\n",
    "    try:\n",
    "        before_batch = np.stack([batch_tuple[0] for batch_tuple in batch_list], axis=0)\n",
    "        after_batch = np.stack([batch_tuple[1] for batch_tuple in batch_list], axis=0)\n",
    "    except:\n",
    "        [print(batch_tuple[0].shape) for batch_tuple in batch_list]\n",
    "        [print(batch_tuple[1].shape) for batch_tuple in batch_list]\n",
    "    return (torch.tensor(before_batch, dtype=torch.float32), torch.tensor(after_batch, dtype=torch.float32))\n",
    "\n",
    "class PunchImageFeeder:\n",
    "    \n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "        self.queue = queue.Queue(maxsize=100)\n",
    "        self.finished = False\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.punch_iter_num = 3\n",
    "        self.max_batch_num = int(np.ceil(len(self.file_list) * (self.punch_iter_num + 1) / self.batch_size))\n",
    "        \n",
    "    def start_feeding(self):\n",
    "        \n",
    "        batch_tuple_list = []\n",
    "        \n",
    "#         for file in self.file_list[::10]:\n",
    "        for file in self.file_list:\n",
    "            image = cv2.imread(file)\n",
    "            image = image[:, :, (2, 1, 0)]\n",
    "            image = image / 2 ** 8\n",
    "            image = np.rollaxis(image, 2, 0)\n",
    "            \n",
    "            image_origin = deepcopy(image)\n",
    "            \n",
    "            batch_tuple_list.append(Batch(image, image))\n",
    "            \n",
    "            for j in range(self.punch_iter_num):\n",
    "#                 punched_image = punch_image(image, 0.15)\n",
    "                punched_image = punch_image(image, 0.1 * (j + 1))\n",
    "                batch_tuple_list.append(Batch(punched_image, image))\n",
    "                \n",
    "                if len(batch_tuple_list) >= self.batch_size:\n",
    "                    random.shuffle(batch_tuple_list)\n",
    "                    batch = batch_list_to_tensor_batch(batch_tuple_list)\n",
    "                    self.queue.put(batch)\n",
    "                    batch_tuple_list = list()\n",
    "                    \n",
    "#                 image = punched_image\n",
    "                \n",
    "        if len(batch_tuple_list) > 0:\n",
    "            random.shuffle(batch_tuple_list)\n",
    "            batch = batch_list_to_tensor_batch(batch_tuple_list)\n",
    "            self.queue.put(batch)\n",
    "            batch_tuple_list = list()\n",
    "                \n",
    "        self.finished = True\n",
    "             \n",
    "    def generator(self):\n",
    "        \n",
    "        self.finished = False\n",
    "        random.shuffle(self.file_list)\n",
    "        \n",
    "        t = threading.Thread(target=self.start_feeding)\n",
    "        t.start()\n",
    "        \n",
    "        while not (self.finished and self.queue.empty()):\n",
    "            try:\n",
    "                batch = self.queue.get_nowait()\n",
    "                yield batch\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "        \n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralImageFeeder:\n",
    "    \n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "        self.queue = queue.Queue(maxsize=100)\n",
    "        self.num_type = 2\n",
    "        self.finished = [False for i in range(self.num_type)]\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.punch_iter_num = 3\n",
    "        self.blur_iter_num = 6\n",
    "        self.max_batch_num = int(np.floor(( \\\n",
    "                                  len(self.file_list) * (self.punch_iter_num + 1) + \\\n",
    "                                  len(self.file_list) * (self.blur_iter_num + 1)) \\\n",
    "                              / self.batch_size))\n",
    "        \n",
    "        \n",
    "    def start_feeding_punch(self):\n",
    "        \n",
    "        batch_tuple_list = []\n",
    "        \n",
    "        for file in self.file_list:\n",
    "            image = cv2.imread(file)\n",
    "            image = image[:, :, (2, 1, 0)]\n",
    "            image = image / 2 ** 8\n",
    "            image = np.rollaxis(image, 2, 0)\n",
    "            \n",
    "            image_origin = deepcopy(image)\n",
    "            \n",
    "            batch_tuple_list.append(Batch(image, image))\n",
    "            \n",
    "            for j in range(self.punch_iter_num):\n",
    "                punched_image = punch_image(image, 0.1 * (j + 1))\n",
    "                batch_tuple_list.append(Batch(punched_image, image))\n",
    "                \n",
    "                if len(batch_tuple_list) >= self.batch_size:\n",
    "                    random.shuffle(batch_tuple_list)\n",
    "                    batch = batch_list_to_tensor_batch(batch_tuple_list)\n",
    "                    self.queue.put(batch)\n",
    "                    batch_tuple_list = list()\n",
    "                \n",
    "        if len(batch_tuple_list) > 0:\n",
    "            random.shuffle(batch_tuple_list)\n",
    "            batch = batch_list_to_tensor_batch(batch_tuple_list)\n",
    "            self.queue.put(batch)\n",
    "            batch_tuple_list = list()\n",
    "                \n",
    "        self.finished[0] = True\n",
    "        \n",
    "    def start_feeding_blur(self):\n",
    "        \n",
    "        batch_tuple_list = []\n",
    "        \n",
    "        for file in self.file_list:\n",
    "            image = cv2.imread(file)\n",
    "            image = image[:, :, (2, 1, 0)]\n",
    "            image = image / 2 ** 8\n",
    "            image = np.rollaxis(image, 2, 0)\n",
    "            \n",
    "            image_origin = deepcopy(image)\n",
    "            \n",
    "            batch_tuple_list.append(Batch(image, image))\n",
    "            \n",
    "            for j in range(self.blur_iter_num):\n",
    "                blurred_image = blur_image(image, 0.25 * (j + 1))\n",
    "                batch_tuple_list.append(Batch(blurred_image, image))\n",
    "                \n",
    "                if len(batch_tuple_list) >= self.batch_size:\n",
    "                    random.shuffle(batch_tuple_list)\n",
    "                    batch = batch_list_to_tensor_batch(batch_tuple_list)\n",
    "                    self.queue.put(batch)\n",
    "                    batch_tuple_list = list()\n",
    "                \n",
    "        if len(batch_tuple_list) > 0:\n",
    "            random.shuffle(batch_tuple_list)\n",
    "            batch = batch_list_to_tensor_batch(batch_tuple_list)\n",
    "            self.queue.put(batch)\n",
    "            batch_tuple_list = list()\n",
    "                \n",
    "        self.finished[1] = True\n",
    "             \n",
    "    def generator(self):\n",
    "        \n",
    "        self.finished = [False for i in range(len(self.finished))]\n",
    "        random.shuffle(self.file_list)\n",
    "        \n",
    "        t1 = threading.Thread(target=self.start_feeding_punch)\n",
    "        t2 = threading.Thread(target=self.start_feeding_blur)\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        \n",
    "        while not (all(self.finished) and self.queue.empty()):\n",
    "            try:\n",
    "                batch = self.queue.get_nowait()\n",
    "                yield batch\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "        \n",
    "        t1.join()\n",
    "        t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punch_image_feeder = PunchImageFeeder(emoticon_file_list)\n",
    "general_image_feeder = GeneralImageFeeder(emoticon_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.functional.pad(torch.tensor(image), (0, 0, 1, 1, 1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, 3, padding=2, padding_mode='circular')\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 3, padding=2, padding_mode='circular')\n",
    "#         self.conv3 = nn.Conv2d(32, 16, 3, padding=2, padding_mode='circular')\n",
    "#         self.conv4 = nn.Conv2d(16, 3, 3, padding=2, padding_mode='circular')\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(3, 128, 3, padding=2, padding_mode='circular')\n",
    "#         self.conv2 = nn.Conv2d(128, 128, 3, padding=2, padding_mode='circular')\n",
    "#         self.conv3 = nn.Conv2d(128, 64, 3, padding=2, padding_mode='circular')\n",
    "#         self.conv4 = nn.Conv2d(64, 3, 3, padding=2, padding_mode='circular')\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=2, padding_mode='circular')\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=2, padding_mode='circular')\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=2, padding_mode='circular')\n",
    "        self.conv4 = nn.Conv2d(64, 3, 3, padding=2, padding_mode='circular')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "#         x = self.conv4(x)\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_history = list()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = ConvNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(150):\n",
    "\n",
    "    for i, batch in tqdm(enumerate(general_image_feeder.generator()), total=general_image_feeder.max_batch_num):\n",
    "\n",
    "        batch_before, batch_after = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_pred = net(batch_before.to(device))\n",
    "#         batch_pred = net(batch_pred) # 2 step prediction\n",
    "#         batch_pred = net(batch_pred) # 3 step prediction\n",
    "#         batch_pred = net(batch_pred) # 4 step prediction\n",
    "\n",
    "        \n",
    "        loss = criterion(batch_pred, batch_after.to(device))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        if i == general_image_feeder.max_batch_num // 2:\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "            axes[0].imshow(np.rollaxis(batch_before.numpy()[0], 0, 3))\n",
    "            axes[1].imshow(np.clip(np.rollaxis(batch_pred.detach().cpu().numpy()[0], 0, 3), 0, 1))\n",
    "            axes[2].imshow(np.rollaxis(batch_after.numpy()[0], 0, 3))\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(12, 2))\n",
    "            plt.plot(loss_history)\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([1e-3, 1e-1])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
